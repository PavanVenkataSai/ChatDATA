# âš¡ ChatPDF-Genius âš¡

Have you ever wanted to talk to your documents like they actually *get you*?  
With **ChatPDF-Genius**, you can ask questions directly to a PDF and get intelligent, context-aware answers â€” all powered by open-source LLMs and RAG (Retrieval-Augmented Generation) techniques. ğŸ§ ğŸ’¬

This version is optimized to work with static PDFs, making it fast, clean, and easy to integrate into any workflow.

If you find this project useful, consider giving it a â­ on GitHub!

---

## ğŸš€ Quick Install

Before you begin, this repo uses LLM models and embedding models from HuggingFace through the inference API. Youâ€™ll need a HuggingFace API token to proceed â€” itâ€™s free and can be created [here](https://huggingface.co/settings/tokens).

### ğŸ” Clone the Repository

```bash
git clone https://github.com/PavanVenkataSai/ChatDATA/.git
cd src
```

## ğŸ“¦ Install Dependencies
This project uses pip for package management. All dependencies are listed in requirements.txt.

```bash

pip install -r requirements.txt
```

```bash

python -m venv .venv
source .venv/bin/activate  # On Windows use: .venv\Scripts\activate
pip install -r requirements.txt
```
â–¶ï¸ Run the App with Streamlit
Launch the chatbot interface:

```bash
streamlit run main_streamlit.py
```
By default, main_streamlit.py is set to use a static PDF path. You can change the file path directly in the script.

## ğŸ“š What's Inside?
This repo uses LangChain as the framework to integrate with open-source LLMs and Retrieval-Augmented Generation (RAG). Here's a brief of what it does:

- ğŸ” PDF Parsing using PyMuPDF

- ğŸ§© Contextual Chunking for better information retrieval

- ğŸ§  FAISS Vector Store for similarity search

- ğŸ¤– Mixtral-8x7B-Instruct from HuggingFace for generating accurate, contextual responses

- ğŸ§¾ Streamlit UI for clean and continuous chat interface

## ğŸ“ Project Structure
```bash
ChatDATA/
â”œâ”€â”€ .gitignore                  # Ignore venv, __pycache__, PDFs, etc.
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ README.md                   # Project documentation
â””â”€â”€ src/                        # Source code folder
    â”œâ”€â”€ generator.py            # Generates final responses using context + LLM
    â”œâ”€â”€ indexing.py             # Indexes chunks into a vector store
    â”œâ”€â”€ load.py                 # Loads and parses the PDF file
    â”œâ”€â”€ split.py                # Splits documents into chunks
    â”œâ”€â”€ retrieve.py             # Retrieves relevant chunks for a given query
    â”œâ”€â”€ main_pdf_web.py         # CLI version with choice of PDF or web input
    â”œâ”€â”€ main_PDF.py             # CLI version for PDF-only flow
    â””â”€â”€ main_streamlit.py       # Streamlit-based chat UI

```
